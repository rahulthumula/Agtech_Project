# -*- coding: utf-8 -*-
"""Untitled44.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fv3eS9xc0s3VmxZWaIkMC5XXu4S-ZS1O
"""

!pip install requests pandas pyyaml beautifulsoup4

import requests
import pandas as pd
import logging
import yaml

# Set up logging
logging.basicConfig(filename='data_collection.log', level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')

# Configuration loading
try:
    with open('config.yaml', 'r') as file:
        config = yaml.safe_load(file)
except FileNotFoundError as e:
    logging.error(f"Configuration file not found: {e}")
    raise
except yaml.YAMLError as e:
    logging.error(f"Error parsing configuration file: {e}")
    raise

def fetch_data(api_url, params):
    try:
        response = requests.get(api_url, params=params)
        response.raise_for_status()  # Check for HTTP errors
        data = response.json()

        # Handle World Bank API structure
        if 'worldbank' in api_url:
            if isinstance(data, list) and len(data) > 1:
                data = data[1]  # The actual data is in the second element of the list
                logging.info(f"Data fetched successfully from {api_url}")
                return pd.DataFrame(data)
            else:
                logging.error(f"No data found in the response from {api_url}")
                return pd.DataFrame()

        # Handle USDA NASS Quick Stats API structure
        if 'data' in data:
            logging.info(f"Data fetched successfully from {api_url}")
            return pd.DataFrame(data['data'])
        else:
            logging.error(f"No 'data' key found in the response from {api_url}")
            return pd.DataFrame()
    except requests.exceptions.RequestException as e:
        logging.error(f"Error fetching data from {api_url}: {e}")
        return pd.DataFrame()

def save_to_csv(data, filename):
    try:
        data.to_csv(filename, index=False)
        logging.info(f"Data saved successfully to {filename}")
    except Exception as e:
        logging.error(f"Error saving data to {filename}: {e}")

def fetch_crop_data_in_chunks(api_url, params, start_year, end_year, commodity_desc):
    all_data = pd.DataFrame()
    for year in range(start_year, end_year + 1):
        for commodity in commodity_desc:
            params['year'] = year
            params['commodity_desc'] = commodity
            yearly_data = fetch_data(api_url, params)
            if not yearly_data.empty:
                all_data = pd.concat([all_data, yearly_data], ignore_index=True)
    return all_data

def main():
    # Fetch Economic Data
    econ_data = fetch_data(config['economic_data']['api_url'], config['economic_data']['params'])
    if not econ_data.empty:
        save_to_csv(econ_data, config['economic_data']['output_file'])

    # Fetch Crop Data in Chunks
    # Check if 'commodity_desc' key exists before accessing it
    if 'commodity_desc' in config['crop_data']:
        crop_data = fetch_crop_data_in_chunks(
            config['crop_data']['api_url'],
            config['crop_data']['params'],
            config['crop_data']['start_year'],
            config['crop_data']['end_year'],
            config['crop_data']['commodity_desc']
        )
        if not crop_data.empty:
            save_to_csv(crop_data, config['crop_data']['output_file'])
    else:
        logging.error("Missing 'commodity_desc' key in 'crop_data' configuration.")

if __name__ == "__main__":
    main()